{"cells":[{"metadata":{"id":"R4i0O4KWvPQx"},"cell_type":"markdown","source":"**Import necessary modules**"},{"metadata":{"id":"x9bOZSrKe5IN","trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport sys\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom matplotlib import pyplot as plt\n%matplotlib inline","execution_count":104,"outputs":[]},{"metadata":{"id":"nXX05s-_e5IS","outputId":"73a21ddb-7cd9-4fe5-b4ac-4d1955175d77","trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')         \nprint(device)","execution_count":105,"outputs":[{"output_type":"stream","text":"cuda\n","name":"stdout"}]},{"metadata":{"id":"rHlzZu4me5IX"},"cell_type":"markdown","source":"# **Dataloading Scheme**"},{"metadata":{"id":"ti28ZpGTe5IY","trusted":true},"cell_type":"code","source":"train_data = np.genfromtxt('../input/digit-recognizer/train.csv', delimiter=',')\ntest_data = np.genfromtxt('../input/digit-recognizer/test.csv', delimiter=',')","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"nbV0Er1EgE-k","trusted":true},"cell_type":"code","source":"train_images = train_data[1:, 1:]\ntrain_labels = train_data[1:, 0]\n\ntest_images = test_data[1:]","execution_count":107,"outputs":[]},{"metadata":{"id":"tq4APCEGvsZJ"},"cell_type":"markdown","source":"*Writing Pytorch custom dataloader using Dataset class and __getitem__ method*"},{"metadata":{"id":"D_HN45Lke5Ij","trusted":true},"cell_type":"code","source":"class my_train_dataset():    \n\n    def __init__(self, train_images, train_labels):\n\n        super(my_train_dataset).__init__()\n        \n        self.X = train_images.reshape(-1,1,28,28)       \n        \n        self.X = torch.from_numpy(self.X).float()\n        self.Y = torch.from_numpy(train_labels).long()\n        \n            \n    def __getitem__(self,index):\n        \n        image = self.X[index]\n        label= self.Y[index]\n\n        return image, label\n        \n    def __len__(self):\n        return len(self.X)\n\n\n\nclass my_test_dataset():    \n\n    def __init__(self, test_images):\n\n        super(my_test_dataset).__init__()\n        \n        self.X = test_images.reshape(-1,1,28,28)       \n        \n        self.X = torch.from_numpy(self.X).float()\n        \n            \n    def __getitem__(self,index):\n        \n        image = self.X[index]\n\n        return image\n        \n    def __len__(self):\n        return len(self.X)","execution_count":108,"outputs":[]},{"metadata":{"id":"SiKeg4Ule5Iv"},"cell_type":"markdown","source":"# **Model Architecture**"},{"metadata":{"id":"MoVJlz_ElO3s","trusted":true},"cell_type":"code","source":"#### Define CNN Model ####\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n      \n        self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(64, 128, 5, padding = 2)\n        self.hidden = nn.Linear(128,64)\n        self.output = nn.Linear(64, 10)\n        # self.dropout = nn.Dropout(0.3)\n\n        \n    def forward(self, x):\n\n        x = F.relu(self.conv1(x))\n        x = self.pool(F.relu(self.conv2(x)))       \n        x = F.relu(self.conv3(x)) \n        x = F.avg_pool2d(x, [x.size(2), x.size(3)], stride=1)\n        x = x.reshape(x.shape[0],x.shape[1])\n        x = self.hidden(x)\n        # x = self.dropout(x)\n        x = self.output(x)\n\n        return x","execution_count":109,"outputs":[]},{"metadata":{"scrolled":true,"id":"Q4Z9ZehQe5JK","outputId":"fde9a436-7368-4760-cebe-131179c3662f","trusted":true},"cell_type":"code","source":"net = Net()\nnet.to(device)\nnet","execution_count":110,"outputs":[{"output_type":"execute_result","execution_count":110,"data":{"text/plain":"Net(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (hidden): Linear(in_features=128, out_features=64, bias=True)\n  (output): Linear(in_features=64, out_features=10, bias=True)\n)"},"metadata":{}}]},{"metadata":{"id":"N1Cso9hhe5JN"},"cell_type":"markdown","source":"# **Training Method**"},{"metadata":{"id":"TPmWu63Me5JO","trusted":true},"cell_type":"code","source":"Training_Loss = []\nTraining_Accuracy = []\n\ndef train(model, data_loader, epochs):\n    net.train()\n    for epoch in range(epochs):\n        avg_loss = 0.0\n        for batch_num, (feats, labels) in enumerate(data_loader):\n            feats, labels = feats.to(device), labels.to(device)\n            \n            outputs = model(feats)\n            loss = criterion(outputs, labels)\n            \n            optimizer.zero_grad()\n            \n            loss.backward()\n            optimizer.step()\n            \n            avg_loss += loss.item()\n\n            if batch_num % 50 == 49:\n                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))\n                avg_loss = 0.0    \n            \n            torch.cuda.empty_cache()\n            del feats\n            del labels\n            del loss\n\n\n        train_loss, train_acc = test_classify(model, data_loader)\n        print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\t'.\n              format(train_loss, train_acc))\n        Training_Loss.append(train_loss)\n        Training_Accuracy.append(train_acc)\n    \n    \n    \ndef test_classify(model, test_loader):\n    model.eval()\n    test_loss = []\n    accuracy = 0\n    total = 0\n\n    for batch_num, (feats, labels) in enumerate(test_loader):\n        feats, labels = feats.to(device), labels.to(device)\n        outputs = model(feats)\n\n        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n        pred_labels = pred_labels.view(-1)\n\n        loss = criterion(outputs, labels.long())\n\n        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n        total += len(labels)\n        test_loss.extend([loss.item()]*feats.size()[0])\n        del feats\n        del labels\n\n    model.train()\n    return np.mean(test_loss), accuracy/total","execution_count":111,"outputs":[]},{"metadata":{"id":"X2-05Qkoe5JR"},"cell_type":"markdown","source":"# **Hyperparameters**"},{"metadata":{"id":"DNj3pjhGe5JR","trusted":true},"cell_type":"code","source":"#Training Batch size\nBatch_size = 256\n\n# Loss Function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer\noptimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n\n# Epochs\nnum_Epochs = 25","execution_count":112,"outputs":[]},{"metadata":{"id":"hSZ9rwtKw-Rg"},"cell_type":"markdown","source":"**Dataloaders**"},{"metadata":{"id":"ugObvOKre5Iq","trusted":true},"cell_type":"code","source":"##### Train Dataloader #### \ntrain_dataset = my_train_dataset(train_images,train_labels)          \ntrain_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = Batch_size, num_workers=4,pin_memory=True)\n\n\n#### Test Dataloader ####\ntest_dataset = my_test_dataset(test_images)\ntest_dataloader = data.DataLoader(test_dataset, shuffle=False, batch_size=1, num_workers=0, pin_memory=True)","execution_count":113,"outputs":[]},{"metadata":{"id":"VMKQuIp-xXNI"},"cell_type":"markdown","source":"**Train the model**"},{"metadata":{"scrolled":false,"id":"zyXSaV2fe5JV","trusted":true},"cell_type":"code","source":"train(net, train_dataloader, epochs = num_Epochs)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch: 1\tBatch: 50\tAvg-Loss: 2.8400\nEpoch: 1\tBatch: 100\tAvg-Loss: 2.2140\nEpoch: 1\tBatch: 150\tAvg-Loss: 1.1780\nTrain Loss: 0.6993\tTrain Accuracy: 0.7608\t\nEpoch: 2\tBatch: 50\tAvg-Loss: 0.4884\nEpoch: 2\tBatch: 100\tAvg-Loss: 0.3369\nEpoch: 2\tBatch: 150\tAvg-Loss: 0.2600\nTrain Loss: 0.3313\tTrain Accuracy: 0.9030\t\nEpoch: 3\tBatch: 50\tAvg-Loss: 0.1989\nEpoch: 3\tBatch: 100\tAvg-Loss: 0.1574\nEpoch: 3\tBatch: 150\tAvg-Loss: 0.1548\nTrain Loss: 0.1060\tTrain Accuracy: 0.9698\t\nEpoch: 4\tBatch: 50\tAvg-Loss: 0.1150\nEpoch: 4\tBatch: 100\tAvg-Loss: 0.1228\nEpoch: 4\tBatch: 150\tAvg-Loss: 0.0961\nTrain Loss: 0.1307\tTrain Accuracy: 0.9581\t\nEpoch: 5\tBatch: 50\tAvg-Loss: 0.1156\nEpoch: 5\tBatch: 100\tAvg-Loss: 0.0846\nEpoch: 5\tBatch: 150\tAvg-Loss: 0.0731\nTrain Loss: 0.0684\tTrain Accuracy: 0.9795\t\nEpoch: 6\tBatch: 50\tAvg-Loss: 0.0777\nEpoch: 6\tBatch: 100\tAvg-Loss: 0.0798\nEpoch: 6\tBatch: 150\tAvg-Loss: 0.0687\nTrain Loss: 0.0808\tTrain Accuracy: 0.9750\t\nEpoch: 7\tBatch: 50\tAvg-Loss: 0.0625\nEpoch: 7\tBatch: 100\tAvg-Loss: 0.0641\nEpoch: 7\tBatch: 150\tAvg-Loss: 0.0602\nTrain Loss: 0.0632\tTrain Accuracy: 0.9806\t\nEpoch: 8\tBatch: 50\tAvg-Loss: 0.0699\nEpoch: 8\tBatch: 100\tAvg-Loss: 0.0545\nEpoch: 8\tBatch: 150\tAvg-Loss: 0.0582\nTrain Loss: 0.0421\tTrain Accuracy: 0.9871\t\nEpoch: 9\tBatch: 50\tAvg-Loss: 0.0628\nEpoch: 9\tBatch: 100\tAvg-Loss: 0.0487\nEpoch: 9\tBatch: 150\tAvg-Loss: 0.0498\nTrain Loss: 0.0702\tTrain Accuracy: 0.9778\t\nEpoch: 10\tBatch: 50\tAvg-Loss: 0.0476\nEpoch: 10\tBatch: 100\tAvg-Loss: 0.0370\nEpoch: 10\tBatch: 150\tAvg-Loss: 0.0519\nTrain Loss: 0.0423\tTrain Accuracy: 0.9871\t\nEpoch: 11\tBatch: 50\tAvg-Loss: 0.0444\nEpoch: 11\tBatch: 100\tAvg-Loss: 0.0388\nEpoch: 11\tBatch: 150\tAvg-Loss: 0.0352\nTrain Loss: 0.0374\tTrain Accuracy: 0.9886\t\nEpoch: 12\tBatch: 50\tAvg-Loss: 0.0422\nEpoch: 12\tBatch: 100\tAvg-Loss: 0.0382\nEpoch: 12\tBatch: 150\tAvg-Loss: 0.0384\nTrain Loss: 0.0390\tTrain Accuracy: 0.9872\t\nEpoch: 13\tBatch: 50\tAvg-Loss: 0.0371\nEpoch: 13\tBatch: 100\tAvg-Loss: 0.0324\nEpoch: 13\tBatch: 150\tAvg-Loss: 0.0325\nTrain Loss: 0.0551\tTrain Accuracy: 0.9830\t\nEpoch: 14\tBatch: 50\tAvg-Loss: 0.0391\nEpoch: 14\tBatch: 100\tAvg-Loss: 0.0374\nEpoch: 14\tBatch: 150\tAvg-Loss: 0.0282\nTrain Loss: 0.0276\tTrain Accuracy: 0.9908\t\nEpoch: 15\tBatch: 50\tAvg-Loss: 0.0313\nEpoch: 15\tBatch: 100\tAvg-Loss: 0.0244\nEpoch: 15\tBatch: 150\tAvg-Loss: 0.0295\nTrain Loss: 0.1332\tTrain Accuracy: 0.9614\t\nEpoch: 16\tBatch: 50\tAvg-Loss: 0.0925\nEpoch: 16\tBatch: 100\tAvg-Loss: 0.0360\nEpoch: 16\tBatch: 150\tAvg-Loss: 0.0304\nTrain Loss: 0.0253\tTrain Accuracy: 0.9919\t\nEpoch: 17\tBatch: 50\tAvg-Loss: 0.0284\nEpoch: 17\tBatch: 100\tAvg-Loss: 0.0241\nEpoch: 17\tBatch: 150\tAvg-Loss: 0.0262\nTrain Loss: 0.0270\tTrain Accuracy: 0.9905\t\nEpoch: 18\tBatch: 50\tAvg-Loss: 0.0288\nEpoch: 18\tBatch: 100\tAvg-Loss: 0.0207\nEpoch: 18\tBatch: 150\tAvg-Loss: 0.0271\nTrain Loss: 0.0254\tTrain Accuracy: 0.9916\t\nEpoch: 19\tBatch: 50\tAvg-Loss: 0.0244\nEpoch: 19\tBatch: 100\tAvg-Loss: 0.0192\nEpoch: 19\tBatch: 150\tAvg-Loss: 0.0279\nTrain Loss: 0.0208\tTrain Accuracy: 0.9930\t\nEpoch: 20\tBatch: 50\tAvg-Loss: 0.0261\nEpoch: 20\tBatch: 100\tAvg-Loss: 0.0240\nEpoch: 20\tBatch: 150\tAvg-Loss: 0.0226\nTrain Loss: 0.0197\tTrain Accuracy: 0.9940\t\nEpoch: 21\tBatch: 50\tAvg-Loss: 0.0170\nEpoch: 21\tBatch: 100\tAvg-Loss: 0.0209\nEpoch: 21\tBatch: 150\tAvg-Loss: 0.0211\nTrain Loss: 0.0159\tTrain Accuracy: 0.9954\t\nEpoch: 22\tBatch: 50\tAvg-Loss: 0.0205\nEpoch: 22\tBatch: 100\tAvg-Loss: 0.0236\nEpoch: 22\tBatch: 150\tAvg-Loss: 0.0201\nTrain Loss: 0.0125\tTrain Accuracy: 0.9960\t\nEpoch: 23\tBatch: 50\tAvg-Loss: 0.0171\nEpoch: 23\tBatch: 100\tAvg-Loss: 0.0229\nEpoch: 23\tBatch: 150\tAvg-Loss: 0.0214\nTrain Loss: 0.0114\tTrain Accuracy: 0.9964\t\nEpoch: 24\tBatch: 50\tAvg-Loss: 0.0218\nEpoch: 24\tBatch: 100\tAvg-Loss: 0.0167\nEpoch: 24\tBatch: 150\tAvg-Loss: 0.0202\n","name":"stdout"}]},{"metadata":{"id":"uikOb2TlwArV"},"cell_type":"markdown","source":"**Predict and write outputs to CSV**"},{"metadata":{"id":"fdtEf0ltwFpE","trusted":true},"cell_type":"code","source":"import csv\n\ndef predict(model, test_loader):\n    \n    model.eval()\n    total = 0\n    index= 1\n    with open('output.csv',mode='w') as output_file:\n      \n        f=csv.writer(output_file,delimiter=',')\n        f.writerow(['ImageId','Label'])\n\n\n        for batch_num, (feats) in enumerate(test_loader):\n            feats = feats.to(device)\n            outputs = model(feats)\n\n            _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n            pred_labels = pred_labels.view(-1)\n\n            f.writerow([str(index), int(pred_labels)])\n            index+=1\n","execution_count":null,"outputs":[]},{"metadata":{"id":"LIAfOCaDe5JZ","trusted":true},"cell_type":"code","source":"predict(net, test_dataloader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss and Accuracy plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nx = np.arange(1,26)\nplt.plot(x, Training_Loss, label = 'Training Loss')\nplt.xlabel('Epochs', fontsize =16)\nplt.ylabel('Loss', fontsize =16)\nplt.title('Loss v/s Epochs',fontsize =16)\nplt.legend(fontsize=16)\n\nplt.figure(figsize=(10,10))\nplt.plot(x, Training_Accuracy, label = 'Training Accuracy')\nplt.xlabel('Epochs', fontsize =16)\nplt.ylabel('Accuracy', fontsize =16)\nplt.title('Accuracy v/s Epochs',fontsize =16)\nplt.legend(fontsize=16)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}